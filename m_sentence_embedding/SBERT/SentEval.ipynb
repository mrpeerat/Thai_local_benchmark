{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import senteval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    batch = [' '.join(sent) if sent != [] else '.' for sent in batch]\n",
    "    embeddings = params['encoder'](batch)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name output/Simcse_original_BERT_original_cls_MLPTrue. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:output/Simcse_original_BERT_original_cls_MLPTrue\n",
      "Total Trainable Params: 109,482,240\n",
      "Model:output/Simcse_original_nreimers_albert_small_v2_cls_MLPTrue\n",
      "Total Trainable Params: 12,274,176\n",
      "Model:output/Simcse_original_nreimers_BERT_Mini_L_4_H_256_A_4_cls_MLPTrue\n",
      "Total Trainable Params: 11,236,352\n",
      "Model:output/Simcse_original_nreimers_MiniLM_L6_H384_uncased_cls_MLPTrue\n",
      "Total Trainable Params: 22,861,056\n",
      "Model:output/Simcse_original_bert_large_uncased_cls_MLPTrue\n",
      "Total Trainable Params: 336,191,488\n",
      "Model:output/Simcse_original_distilbert_base_cased_cls_MLPTrue\n",
      "Total Trainable Params: 65,781,504\n",
      "Model:output/Simcse_original_nreimers_TinyBERT_L_4_H_312_v2_cls_MLPTrue\n",
      "Total Trainable Params: 14,447,904\n",
      "Model:output/Simcse_original_roberta_base_cls_MLPTrue\n",
      "Total Trainable Params: 125,236,224\n",
      "Model:output/Simcse_original_nreimers_BERT_Tiny_L_2_H_128_A_2_cls_MLPTrue\n",
      "Total Trainable Params: 4,402,432\n",
      "Model:output/Simcse_original_roberta_large_cls_MLPTrue\n",
      "Total Trainable Params: 356,409,344\n",
      "Model:output/Simcse_original_google_mobilebert_uncased_cls_MLPTrue\n",
      "Total Trainable Params: 24,844,544\n",
      "Model:output/Simcse_original_nreimers_BERT_Small_L_4_H_512_A_8_cls_MLPTrue\n",
      "Total Trainable Params: 29,026,304\n",
      "Model:output/Simcse_original_bert_base_uncased_cls_MLPTrue\n",
      "Total Trainable Params: 110,072,832\n",
      "Model:output/Simcse_original_nreimers_TinyBERT_L_6_H_768_v2_cls_MLPTrue\n",
      "Total Trainable Params: 67,545,600\n",
      "Model:output/Simcse_original_nreimers_MiniLM_L3_H384_uncased_cls_MLPTrue\n",
      "Total Trainable Params: 17,537,664\n",
      "Model:output/Simcse_original_microsoft_MiniLM_L12_H384_uncased_cls_MLPTrue\n",
      "Total Trainable Params: 33,507,840\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: \n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "#     print(table)\n",
    "    print(f\"Total Trainable Params: {total_params:,}\")\n",
    "    return total_params\n",
    "\n",
    "pool_mode='cls'\n",
    "mlp_mode=True\n",
    "model_list = glob(f'output/Simcse_original_*{pool_mode}*MLP{mlp_mode}*')\n",
    "for m in model_list[:]:\n",
    "    print(f\"Model:{m}\")\n",
    "    sim_cse = SentenceTransformer(m)\n",
    "    \n",
    "    count_parameters(sim_cse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Mono T = SimCSE(Wiki) S = small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/m_sentence_embedding/SBERT/SentEval/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "/workspace/m_sentence_embedding/SBERT/SentEval/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-nreimers-BERT-Tiny_L-2_H-128_A-2\n",
      "STS12\n",
      "Spearman:70.78\n",
      "STS13\n",
      "Spearman:78.98\n",
      "STS14\n",
      "Spearman:70.98\n",
      "STS15\n",
      "Spearman:78.58\n",
      "STS16\n",
      "Spearman:74.61\n",
      "STSBenchmark\n",
      "Spearman:73.42\n",
      "SICKRelatedness\n",
      "Spearman:67.43\n",
      "Avg:73.54\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-distilbert-base-cased\n",
      "STS12\n",
      "Spearman:72.64\n",
      "STS13\n",
      "Spearman:84.11\n",
      "STS14\n",
      "Spearman:75.86\n",
      "STS15\n",
      "Spearman:83.35\n",
      "STS16\n",
      "Spearman:79.10\n",
      "STSBenchmark\n",
      "Spearman:80.53\n",
      "SICKRelatedness\n",
      "Spearman:70.07\n",
      "Avg:77.95\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-nreimers-TinyBERT_L-6_H-768_v2\n",
      "STS12\n",
      "Spearman:72.28\n",
      "STS13\n",
      "Spearman:84.38\n",
      "STS14\n",
      "Spearman:76.77\n",
      "STS15\n",
      "Spearman:84.91\n",
      "STS16\n",
      "Spearman:79.89\n",
      "STSBenchmark\n",
      "Spearman:81.23\n",
      "SICKRelatedness\n",
      "Spearman:70.70\n",
      "Avg:78.59\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-nreimers-BERT-Mini_L-4_H-256_A-4\n",
      "STS12\n",
      "Spearman:71.14\n",
      "STS13\n",
      "Spearman:82.19\n",
      "STS14\n",
      "Spearman:73.88\n",
      "STS15\n",
      "Spearman:82.61\n",
      "STS16\n",
      "Spearman:76.90\n",
      "STSBenchmark\n",
      "Spearman:77.76\n",
      "SICKRelatedness\n",
      "Spearman:68.87\n",
      "Avg:76.19\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-nreimers-MiniLM-L6-H384-uncased\n",
      "STS12\n",
      "Spearman:70.05\n",
      "STS13\n",
      "Spearman:83.77\n",
      "STS14\n",
      "Spearman:75.68\n",
      "STS15\n",
      "Spearman:83.82\n",
      "STS16\n",
      "Spearman:78.35\n",
      "STSBenchmark\n",
      "Spearman:80.14\n",
      "SICKRelatedness\n",
      "Spearman:69.84\n",
      "Avg:77.38\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-Simcse_original_roberta_large_cls_MLPTrue-S-bert-base-cased\n",
      "STS12\n",
      "Spearman:72.94\n",
      "STS13\n",
      "Spearman:84.29\n",
      "STS14\n",
      "Spearman:76.58\n",
      "STS15\n",
      "Spearman:84.22\n",
      "STS16\n",
      "Spearman:79.51\n",
      "STSBenchmark\n",
      "Spearman:81.18\n",
      "SICKRelatedness\n",
      "Spearman:70.48\n",
      "Avg:78.46\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-microsoft-MiniLM-L12-H384-uncased\n",
      "STS12\n",
      "Spearman:72.37\n",
      "STS13\n",
      "Spearman:84.65\n",
      "STS14\n",
      "Spearman:77.02\n",
      "STS15\n",
      "Spearman:85.02\n",
      "STS16\n",
      "Spearman:79.90\n",
      "STSBenchmark\n",
      "Spearman:81.67\n",
      "SICKRelatedness\n",
      "Spearman:70.76\n",
      "Avg:78.77\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-nreimers-BERT-Small-L-4_H-512_A-8\n",
      "STS12\n",
      "Spearman:70.30\n",
      "STS13\n",
      "Spearman:83.13\n",
      "STS14\n",
      "Spearman:75.40\n",
      "STS15\n",
      "Spearman:83.70\n",
      "STS16\n",
      "Spearman:78.23\n",
      "STSBenchmark\n",
      "Spearman:79.44\n",
      "SICKRelatedness\n",
      "Spearman:69.42\n",
      "Avg:77.09\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-nreimers-TinyBERT_L-4_H-312_v2\n",
      "STS12\n",
      "Spearman:69.63\n",
      "STS13\n",
      "Spearman:82.82\n",
      "STS14\n",
      "Spearman:74.95\n",
      "STS15\n",
      "Spearman:83.17\n",
      "STS16\n",
      "Spearman:78.39\n",
      "STSBenchmark\n",
      "Spearman:79.66\n",
      "SICKRelatedness\n",
      "Spearman:69.73\n",
      "Avg:76.91\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-google-mobilebert-uncased\n",
      "STS12\n",
      "Spearman:12.87\n",
      "STS13\n",
      "Spearman:19.46\n",
      "STS14\n",
      "Spearman:7.38\n",
      "STS15\n",
      "Spearman:5.23\n",
      "STS16\n",
      "Spearman:14.31\n",
      "STSBenchmark\n",
      "Spearman:8.70\n",
      "SICKRelatedness\n",
      "Spearman:15.47\n",
      "Avg:11.92\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-nreimers-albert-small-v2\n",
      "STS12\n",
      "Spearman:69.35\n",
      "STS13\n",
      "Spearman:82.97\n",
      "STS14\n",
      "Spearman:73.96\n",
      "STS15\n",
      "Spearman:82.95\n",
      "STS16\n",
      "Spearman:78.56\n",
      "STSBenchmark\n",
      "Spearman:79.48\n",
      "SICKRelatedness\n",
      "Spearman:69.41\n",
      "Avg:76.67\n",
      "**************************************************\n",
      "\n",
      "Model:output/l2_mono/L2-T-output-simcse_original-Simcse_original_roberta_large_cls_MLPTrue-S-nreimers-MiniLM-L3-H384-uncased\n",
      "STS12\n",
      "Spearman:69.89\n",
      "STS13\n",
      "Spearman:82.49\n",
      "STS14\n",
      "Spearman:74.79\n",
      "STS15\n",
      "Spearman:83.16\n",
      "STS16\n",
      "Spearman:77.90\n",
      "STSBenchmark\n",
      "Spearman:78.58\n",
      "SICKRelatedness\n",
      "Spearman:69.15\n",
      "Avg:76.57\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pool_mode = 'cls'\n",
    "mlp_mode = True\n",
    "model_list = glob(f'output/l2_mono/L2-T*')\n",
    "# making-T-output-Simcse_original_roberta_large_cls_MLPTrue-S-bert-base-cased\n",
    "for model in model_list:\n",
    "    try:\n",
    "        word_embedding_model = models.Transformer(model, max_seq_length=32)\n",
    "        pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "        sim_cse = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    except:\n",
    "        sim_cse = SentenceTransformer(model)\n",
    "    \n",
    "    params = {'task_path': 'SentEval/data/', 'usepytorch': True, 'kfold': 10}\n",
    "    params['encoder'] = sim_cse.encode\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "\n",
    "    transfer_tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    results = se.eval(transfer_tasks)\n",
    "\n",
    "    print(f\"Model:{model}\")\n",
    "    spearman_val = 0\n",
    "    for key in results.keys():\n",
    "        print(key)\n",
    "    #     print(results)\n",
    "        if key not in ['STSBenchmark','SICKRelatedness']:\n",
    "            result_temp = results[key]['all']['spearman']['all']\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "        else:\n",
    "            result_temp = results[key]['test']['spearman'].correlation\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "    print(f\"Avg:{(spearman_val/len(results.keys()))*100:.2f}\")\n",
    "    print(f\"*\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCSE+BSL+Distill Mono T = SimCSE(Wiki) S = small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_nreimers_BERT_Mini_L_4_H_256_A_4_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:75.19\n",
      "STS13\n",
      "Spearman:81.98\n",
      "STS14\n",
      "Spearman:76.03\n",
      "STS15\n",
      "Spearman:83.63\n",
      "STS16\n",
      "Spearman:77.31\n",
      "STSBenchmark\n",
      "Spearman:79.76\n",
      "SICKRelatedness\n",
      "Spearman:70.69\n",
      "Avg:77.80\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_nreimers_TinyBERT_L_4_H_312_v2_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:75.63\n",
      "STS13\n",
      "Spearman:82.69\n",
      "STS14\n",
      "Spearman:76.38\n",
      "STS15\n",
      "Spearman:84.19\n",
      "STS16\n",
      "Spearman:78.99\n",
      "STSBenchmark\n",
      "Spearman:80.22\n",
      "SICKRelatedness\n",
      "Spearman:70.71\n",
      "Avg:78.40\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_distilbert_base_cased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:77.73\n",
      "STS13\n",
      "Spearman:83.99\n",
      "STS14\n",
      "Spearman:77.27\n",
      "STS15\n",
      "Spearman:84.32\n",
      "STS16\n",
      "Spearman:79.36\n",
      "STSBenchmark\n",
      "Spearman:80.93\n",
      "SICKRelatedness\n",
      "Spearman:71.11\n",
      "Avg:79.24\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_nreimers_MiniLM_L6_H384_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:76.32\n",
      "STS13\n",
      "Spearman:83.93\n",
      "STS14\n",
      "Spearman:77.60\n",
      "STS15\n",
      "Spearman:84.80\n",
      "STS16\n",
      "Spearman:79.33\n",
      "STSBenchmark\n",
      "Spearman:81.53\n",
      "SICKRelatedness\n",
      "Spearman:71.30\n",
      "Avg:79.26\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_microsoft_MiniLM_L12_H384_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:76.77\n",
      "STS13\n",
      "Spearman:84.98\n",
      "STS14\n",
      "Spearman:77.86\n",
      "STS15\n",
      "Spearman:85.48\n",
      "STS16\n",
      "Spearman:80.17\n",
      "STSBenchmark\n",
      "Spearman:82.24\n",
      "SICKRelatedness\n",
      "Spearman:72.39\n",
      "Avg:79.98\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_nreimers_TinyBERT_L_6_H_768_v2_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:77.16\n",
      "STS13\n",
      "Spearman:85.25\n",
      "STS14\n",
      "Spearman:78.01\n",
      "STS15\n",
      "Spearman:85.56\n",
      "STS16\n",
      "Spearman:79.72\n",
      "STSBenchmark\n",
      "Spearman:81.86\n",
      "SICKRelatedness\n",
      "Spearman:71.92\n",
      "Avg:79.92\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_nreimers_MiniLM_L3_H384_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:74.43\n",
      "STS13\n",
      "Spearman:82.51\n",
      "STS14\n",
      "Spearman:76.13\n",
      "STS15\n",
      "Spearman:83.59\n",
      "STS16\n",
      "Spearman:78.68\n",
      "STSBenchmark\n",
      "Spearman:80.18\n",
      "SICKRelatedness\n",
      "Spearman:70.57\n",
      "Avg:78.01\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_bert_base_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:77.55\n",
      "STS13\n",
      "Spearman:85.50\n",
      "STS14\n",
      "Spearman:78.41\n",
      "STS15\n",
      "Spearman:85.35\n",
      "STS16\n",
      "Spearman:80.22\n",
      "STSBenchmark\n",
      "Spearman:82.53\n",
      "SICKRelatedness\n",
      "Spearman:72.17\n",
      "Avg:80.25\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_nreimers_BERT_Small_L_4_H_512_A_8_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:76.07\n",
      "STS13\n",
      "Spearman:83.49\n",
      "STS14\n",
      "Spearman:77.12\n",
      "STS15\n",
      "Spearman:84.65\n",
      "STS16\n",
      "Spearman:78.49\n",
      "STSBenchmark\n",
      "Spearman:80.58\n",
      "SICKRelatedness\n",
      "Spearman:71.18\n",
      "Avg:78.80\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_nreimers_BERT_Tiny_L_2_H_128_A_2_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:73.87\n",
      "STS13\n",
      "Spearman:80.40\n",
      "STS14\n",
      "Spearman:74.65\n",
      "STS15\n",
      "Spearman:82.86\n",
      "STS16\n",
      "Spearman:76.52\n",
      "STSBenchmark\n",
      "Spearman:77.81\n",
      "SICKRelatedness\n",
      "Spearman:69.22\n",
      "Avg:76.48\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-test-T-princeton-nlp-unsup-simcse-roberta-large-S--Simcse_original_nreimers_albert_small_v2_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:76.88\n",
      "STS13\n",
      "Spearman:81.41\n",
      "STS14\n",
      "Spearman:76.26\n",
      "STS15\n",
      "Spearman:84.24\n",
      "STS16\n",
      "Spearman:78.08\n",
      "STSBenchmark\n",
      "Spearman:81.11\n",
      "SICKRelatedness\n",
      "Spearman:71.20\n",
      "Avg:78.45\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pool_mode = 'cls'\n",
    "mlp_mode = True\n",
    "model_list = glob(f'output/bsl_mono_distill/BSL_making-test-T-*-S*')\n",
    "# making-T-output-Simcse_original_roberta_large_cls_MLPTrue-S-bert-base-cased\n",
    "for model in model_list:\n",
    "    print(f\"Model:{model}\")\n",
    "#     word_embedding_model = models.Transformer(model, max_seq_length=32)\n",
    "#     pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "#     sim_cse = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    sim_cse = SentenceTransformer(model)\n",
    "    \n",
    "    params = {'task_path': 'SentEval/data/', 'usepytorch': True, 'kfold': 10}\n",
    "    params['encoder'] = sim_cse.encode\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "\n",
    "    transfer_tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    results = se.eval(transfer_tasks)\n",
    "\n",
    "    \n",
    "    spearman_val = 0\n",
    "    for key in results.keys():\n",
    "        print(key)\n",
    "    #     print(results)\n",
    "        if key not in ['STSBenchmark','SICKRelatedness']:\n",
    "            result_temp = results[key]['all']['spearman']['all']\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "        else:\n",
    "            result_temp = results[key]['test']['spearman'].correlation\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "    print(f\"Avg:{(spearman_val/len(results.keys()))*100:.2f}\")\n",
    "    print(f\"*\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BSL+Distill Mono T = SimCSE(Wiki) S = small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-BERT-Tiny_L-2_H-128_A-2\n",
      "STS12\n",
      "Spearman:73.63\n",
      "STS13\n",
      "Spearman:80.76\n",
      "STS14\n",
      "Spearman:74.63\n",
      "STS15\n",
      "Spearman:82.39\n",
      "STS16\n",
      "Spearman:76.08\n",
      "STSBenchmark\n",
      "Spearman:77.84\n",
      "SICKRelatedness\n",
      "Spearman:69.15\n",
      "Avg:76.35\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-TinyBERT_L-4_H-312_v2\n",
      "STS12\n",
      "Spearman:75.42\n",
      "STS13\n",
      "Spearman:82.47\n",
      "STS14\n",
      "Spearman:76.60\n",
      "STS15\n",
      "Spearman:84.32\n",
      "STS16\n",
      "Spearman:78.96\n",
      "STSBenchmark\n",
      "Spearman:80.33\n",
      "SICKRelatedness\n",
      "Spearman:70.96\n",
      "Avg:78.44\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-distilbert-base-cased\n",
      "STS12\n",
      "Spearman:77.57\n",
      "STS13\n",
      "Spearman:83.73\n",
      "STS14\n",
      "Spearman:77.48\n",
      "STS15\n",
      "Spearman:84.21\n",
      "STS16\n",
      "Spearman:79.35\n",
      "STSBenchmark\n",
      "Spearman:81.38\n",
      "SICKRelatedness\n",
      "Spearman:71.28\n",
      "Avg:79.29\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-microsoft-MiniLM-L12-H384-uncased\n",
      "STS12\n",
      "Spearman:76.88\n",
      "STS13\n",
      "Spearman:84.89\n",
      "STS14\n",
      "Spearman:78.19\n",
      "STS15\n",
      "Spearman:85.74\n",
      "STS16\n",
      "Spearman:80.24\n",
      "STSBenchmark\n",
      "Spearman:82.40\n",
      "SICKRelatedness\n",
      "Spearman:71.98\n",
      "Avg:80.04\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-albert-small-v2\n",
      "STS12\n",
      "Spearman:76.53\n",
      "STS13\n",
      "Spearman:81.42\n",
      "STS14\n",
      "Spearman:76.88\n",
      "STS15\n",
      "Spearman:83.98\n",
      "STS16\n",
      "Spearman:78.58\n",
      "STSBenchmark\n",
      "Spearman:80.97\n",
      "SICKRelatedness\n",
      "Spearman:71.23\n",
      "Avg:78.51\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-bert-base-uncased\n",
      "STS12\n",
      "Spearman:77.78\n",
      "STS13\n",
      "Spearman:85.55\n",
      "STS14\n",
      "Spearman:78.06\n",
      "STS15\n",
      "Spearman:85.40\n",
      "STS16\n",
      "Spearman:80.61\n",
      "STSBenchmark\n",
      "Spearman:82.44\n",
      "SICKRelatedness\n",
      "Spearman:72.00\n",
      "Avg:80.26\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-BERT-Mini_L-4_H-256_A-4\n",
      "STS12\n",
      "Spearman:74.83\n",
      "STS13\n",
      "Spearman:82.31\n",
      "STS14\n",
      "Spearman:75.90\n",
      "STS15\n",
      "Spearman:83.62\n",
      "STS16\n",
      "Spearman:77.57\n",
      "STSBenchmark\n",
      "Spearman:79.79\n",
      "SICKRelatedness\n",
      "Spearman:70.59\n",
      "Avg:77.80\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-MiniLM-L6-H384-uncased\n",
      "STS12\n",
      "Spearman:75.94\n",
      "STS13\n",
      "Spearman:83.89\n",
      "STS14\n",
      "Spearman:77.56\n",
      "STS15\n",
      "Spearman:85.22\n",
      "STS16\n",
      "Spearman:79.40\n",
      "STSBenchmark\n",
      "Spearman:81.63\n",
      "SICKRelatedness\n",
      "Spearman:71.31\n",
      "Avg:79.28\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-roberta-base\n",
      "STS12\n",
      "Spearman:77.42\n",
      "STS13\n",
      "Spearman:84.68\n",
      "STS14\n",
      "Spearman:76.65\n",
      "STS15\n",
      "Spearman:85.43\n",
      "STS16\n",
      "Spearman:80.95\n",
      "STSBenchmark\n",
      "Spearman:82.70\n",
      "SICKRelatedness\n",
      "Spearman:71.70\n",
      "Avg:79.93\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-BERT-Small-L-4_H-512_A-8\n",
      "STS12\n",
      "Spearman:75.70\n",
      "STS13\n",
      "Spearman:83.47\n",
      "STS14\n",
      "Spearman:77.17\n",
      "STS15\n",
      "Spearman:84.71\n",
      "STS16\n",
      "Spearman:78.70\n",
      "STSBenchmark\n",
      "Spearman:81.25\n",
      "SICKRelatedness\n",
      "Spearman:70.93\n",
      "Avg:78.85\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-MiniLM-L3-H384-uncased\n",
      "STS12\n",
      "Spearman:74.03\n",
      "STS13\n",
      "Spearman:82.73\n",
      "STS14\n",
      "Spearman:76.08\n",
      "STS15\n",
      "Spearman:84.16\n",
      "STS16\n",
      "Spearman:78.88\n",
      "STSBenchmark\n",
      "Spearman:80.24\n",
      "SICKRelatedness\n",
      "Spearman:70.53\n",
      "Avg:78.09\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_mono_distill/BSL_making-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-TinyBERT_L-6_H-768_v2\n",
      "STS12\n",
      "Spearman:77.23\n",
      "STS13\n",
      "Spearman:85.13\n",
      "STS14\n",
      "Spearman:78.01\n",
      "STS15\n",
      "Spearman:85.64\n",
      "STS16\n",
      "Spearman:79.67\n",
      "STSBenchmark\n",
      "Spearman:82.07\n",
      "SICKRelatedness\n",
      "Spearman:71.65\n",
      "Avg:79.91\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pool_mode = 'cls'\n",
    "mlp_mode = True\n",
    "model_list = glob(f'output/bsl_mono_distill/BSL_making-T-*-S*')\n",
    "# making-T-output-Simcse_original_roberta_large_cls_MLPTrue-S-bert-base-cased\n",
    "for model in model_list:\n",
    "    print(f\"Model:{model}\")\n",
    "#     word_embedding_model = models.Transformer(model, max_seq_length=32)\n",
    "#     pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "#     sim_cse = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    sim_cse = SentenceTransformer(model)\n",
    "    \n",
    "    params = {'task_path': 'SentEval/data/', 'usepytorch': True, 'kfold': 10}\n",
    "    params['encoder'] = sim_cse.encode\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "\n",
    "    transfer_tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    results = se.eval(transfer_tasks)\n",
    "\n",
    "    \n",
    "    spearman_val = 0\n",
    "    for key in results.keys():\n",
    "        print(key)\n",
    "    #     print(results)\n",
    "        if key not in ['STSBenchmark','SICKRelatedness']:\n",
    "            result_temp = results[key]['all']['spearman']['all']\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "        else:\n",
    "            result_temp = results[key]['test']['spearman'].correlation\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "    print(f\"Avg:{(spearman_val/len(results.keys()))*100:.2f}\")\n",
    "    print(f\"*\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKD distill T=Robert-Large (SimCSE-wiki1M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-MiniLM-L6-H384-uncased\n",
      "STS12\n",
      "Spearman:67.87\n",
      "STS13\n",
      "Spearman:78.04\n",
      "STS14\n",
      "Spearman:68.79\n",
      "STS15\n",
      "Spearman:77.13\n",
      "STS16\n",
      "Spearman:70.63\n",
      "STSBenchmark\n",
      "Spearman:72.21\n",
      "SICKRelatedness\n",
      "Spearman:67.86\n",
      "Avg:71.79\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-distilbert-base-cased\n",
      "STS12\n",
      "Spearman:72.63\n",
      "STS13\n",
      "Spearman:80.98\n",
      "STS14\n",
      "Spearman:72.40\n",
      "STS15\n",
      "Spearman:79.42\n",
      "STS16\n",
      "Spearman:74.25\n",
      "STSBenchmark\n",
      "Spearman:76.16\n",
      "SICKRelatedness\n",
      "Spearman:68.79\n",
      "Avg:74.95\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-MiniLM-L3-H384-uncased\n",
      "STS12\n",
      "Spearman:69.34\n",
      "STS13\n",
      "Spearman:78.35\n",
      "STS14\n",
      "Spearman:70.17\n",
      "STS15\n",
      "Spearman:79.35\n",
      "STS16\n",
      "Spearman:71.64\n",
      "STSBenchmark\n",
      "Spearman:72.39\n",
      "SICKRelatedness\n",
      "Spearman:66.18\n",
      "Avg:72.49\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-TinyBERT_L-6_H-768_v2\n",
      "STS12\n",
      "Spearman:72.73\n",
      "STS13\n",
      "Spearman:82.82\n",
      "STS14\n",
      "Spearman:73.87\n",
      "STS15\n",
      "Spearman:81.69\n",
      "STS16\n",
      "Spearman:76.38\n",
      "STSBenchmark\n",
      "Spearman:77.29\n",
      "SICKRelatedness\n",
      "Spearman:70.06\n",
      "Avg:76.41\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-TinyBERT_L-4_H-312_v2\n",
      "STS12\n",
      "Spearman:70.47\n",
      "STS13\n",
      "Spearman:77.73\n",
      "STS14\n",
      "Spearman:70.07\n",
      "STS15\n",
      "Spearman:78.05\n",
      "STS16\n",
      "Spearman:71.99\n",
      "STSBenchmark\n",
      "Spearman:72.66\n",
      "SICKRelatedness\n",
      "Spearman:67.35\n",
      "Avg:72.62\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-albert-small-v2\n",
      "STS12\n",
      "Spearman:71.84\n",
      "STS13\n",
      "Spearman:78.38\n",
      "STS14\n",
      "Spearman:71.88\n",
      "STS15\n",
      "Spearman:80.80\n",
      "STS16\n",
      "Spearman:76.31\n",
      "STSBenchmark\n",
      "Spearman:75.60\n",
      "SICKRelatedness\n",
      "Spearman:68.24\n",
      "Avg:74.72\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-BERT-Tiny_L-2_H-128_A-2\n",
      "STS12\n",
      "Spearman:65.95\n",
      "STS13\n",
      "Spearman:74.44\n",
      "STS14\n",
      "Spearman:65.26\n",
      "STS15\n",
      "Spearman:74.86\n",
      "STS16\n",
      "Spearman:68.46\n",
      "STSBenchmark\n",
      "Spearman:69.05\n",
      "SICKRelatedness\n",
      "Spearman:66.08\n",
      "Avg:69.16\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-BERT-Mini_L-4_H-256_A-4\n",
      "STS12\n",
      "Spearman:51.26\n",
      "STS13\n",
      "Spearman:57.65\n",
      "STS14\n",
      "Spearman:52.55\n",
      "STS15\n",
      "Spearman:67.96\n",
      "STS16\n",
      "Spearman:59.89\n",
      "STSBenchmark\n",
      "Spearman:53.90\n",
      "SICKRelatedness\n",
      "Spearman:61.62\n",
      "Avg:57.83\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-bert-base-uncased\n",
      "STS12\n",
      "Spearman:70.60\n",
      "STS13\n",
      "Spearman:80.78\n",
      "STS14\n",
      "Spearman:70.95\n",
      "STS15\n",
      "Spearman:77.91\n",
      "STS16\n",
      "Spearman:74.79\n",
      "STSBenchmark\n",
      "Spearman:76.57\n",
      "SICKRelatedness\n",
      "Spearman:69.61\n",
      "Avg:74.46\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-nreimers-BERT-Small-L-4_H-512_A-8\n",
      "STS12\n",
      "Spearman:70.15\n",
      "STS13\n",
      "Spearman:78.97\n",
      "STS14\n",
      "Spearman:70.15\n",
      "STS15\n",
      "Spearman:78.88\n",
      "STS16\n",
      "Spearman:72.05\n",
      "STSBenchmark\n",
      "Spearman:73.74\n",
      "SICKRelatedness\n",
      "Spearman:68.88\n",
      "Avg:73.26\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-roberta-base\n",
      "STS12\n",
      "Spearman:67.69\n",
      "STS13\n",
      "Spearman:79.16\n",
      "STS14\n",
      "Spearman:68.90\n",
      "STS15\n",
      "Spearman:77.67\n",
      "STS16\n",
      "Spearman:74.28\n",
      "STSBenchmark\n",
      "Spearman:73.50\n",
      "SICKRelatedness\n",
      "Spearman:68.52\n",
      "Avg:72.82\n",
      "**************************************************\n",
      "\n",
      "Model:output/skd/skd_mono-T-princeton-nlp-unsup-simcse-roberta-large-S-microsoft-MiniLM-L12-H384-uncased\n",
      "STS12\n",
      "Spearman:66.55\n",
      "STS13\n",
      "Spearman:78.40\n",
      "STS14\n",
      "Spearman:67.74\n",
      "STS15\n",
      "Spearman:76.25\n",
      "STS16\n",
      "Spearman:70.96\n",
      "STSBenchmark\n",
      "Spearman:71.51\n",
      "SICKRelatedness\n",
      "Spearman:68.38\n",
      "Avg:71.40\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pool_mode = 'cls'\n",
    "mlp_mode = True\n",
    "model_list = glob(f'output/skd/skd_mono-T*')\n",
    "# making-T-output-Simcse_original_roberta_large_cls_MLPTrue-S-bert-base-cased\n",
    "for model in model_list:\n",
    "#     word_embedding_model = models.Transformer(model, max_seq_length=32)\n",
    "#     pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "#     sim_cse = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    sim_cse = SentenceTransformer(model)\n",
    "    \n",
    "    params = {'task_path': 'SentEval/data/', 'usepytorch': True, 'kfold': 10}\n",
    "    params['encoder'] = sim_cse.encode\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "\n",
    "    transfer_tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    results = se.eval(transfer_tasks)\n",
    "\n",
    "    print(f\"Model:{model}\")\n",
    "    spearman_val = 0\n",
    "    for key in results.keys():\n",
    "        print(key)\n",
    "    #     print(results)\n",
    "        if key not in ['STSBenchmark','SICKRelatedness']:\n",
    "            result_temp = results[key]['all']['spearman']['all']\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "        else:\n",
    "            result_temp = results[key]['test']['spearman'].correlation\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "    print(f\"Avg:{(spearman_val/len(results.keys()))*100:.2f}\")\n",
    "    print(f\"*\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BSL original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:output/bsl_original/BSL_unsup_tuning-nreimers-TinyBERT_L-6_H-768_v2\n",
      "STS12\n",
      "Spearman:71.20\n",
      "STS13\n",
      "Spearman:68.56\n",
      "STS14\n",
      "Spearman:66.96\n",
      "STS15\n",
      "Spearman:79.78\n",
      "STS16\n",
      "Spearman:74.17\n",
      "STSBenchmark\n",
      "Spearman:74.68\n",
      "SICKRelatedness\n",
      "Spearman:67.92\n",
      "Avg:71.89\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_original/BSL_unsup_tuning-microsoft-MiniLM-L12-H384-uncased\n",
      "STS12\n",
      "Spearman:61.62\n",
      "STS13\n",
      "Spearman:59.90\n",
      "STS14\n",
      "Spearman:54.95\n",
      "STS15\n",
      "Spearman:72.29\n",
      "STS16\n",
      "Spearman:67.14\n",
      "STSBenchmark\n",
      "Spearman:67.57\n",
      "SICKRelatedness\n",
      "Spearman:64.45\n",
      "Avg:63.99\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_original/BSL_unsup_tuning-nreimers-TinyBERT_L-4_H-312_v2\n",
      "STS12\n",
      "Spearman:67.46\n",
      "STS13\n",
      "Spearman:59.80\n",
      "STS14\n",
      "Spearman:59.99\n",
      "STS15\n",
      "Spearman:77.18\n",
      "STS16\n",
      "Spearman:69.56\n",
      "STSBenchmark\n",
      "Spearman:70.50\n",
      "SICKRelatedness\n",
      "Spearman:67.14\n",
      "Avg:67.38\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_original/BSL_unsup_tuning-nreimers-BERT-Tiny_L-2_H-128_A-2\n",
      "STS12\n",
      "Spearman:65.57\n",
      "STS13\n",
      "Spearman:68.52\n",
      "STS14\n",
      "Spearman:62.82\n",
      "STS15\n",
      "Spearman:76.73\n",
      "STS16\n",
      "Spearman:69.57\n",
      "STSBenchmark\n",
      "Spearman:67.50\n",
      "SICKRelatedness\n",
      "Spearman:62.50\n",
      "Avg:67.60\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_original/BSL_unsup_tuning-distilbert-base-cased\n",
      "STS12\n",
      "Spearman:72.70\n",
      "STS13\n",
      "Spearman:67.04\n",
      "STS14\n",
      "Spearman:68.39\n",
      "STS15\n",
      "Spearman:78.13\n",
      "STS16\n",
      "Spearman:73.71\n",
      "STSBenchmark\n",
      "Spearman:74.84\n",
      "SICKRelatedness\n",
      "Spearman:66.29\n",
      "Avg:71.58\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_original/BSL_unsup_tuning-nreimers-MiniLM-L3-H384-uncased\n",
      "STS12\n",
      "Spearman:68.64\n",
      "STS13\n",
      "Spearman:57.37\n",
      "STS14\n",
      "Spearman:58.53\n",
      "STS15\n",
      "Spearman:73.77\n",
      "STS16\n",
      "Spearman:65.46\n",
      "STSBenchmark\n",
      "Spearman:67.65\n",
      "SICKRelatedness\n",
      "Spearman:63.12\n",
      "Avg:64.93\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_original/BSL_unsup_tuning-nreimers-BERT-Mini_L-4_H-256_A-4\n",
      "STS12\n",
      "Spearman:68.91\n",
      "STS13\n",
      "Spearman:63.94\n",
      "STS14\n",
      "Spearman:63.56\n",
      "STS15\n",
      "Spearman:78.45\n",
      "STS16\n",
      "Spearman:73.19\n",
      "STSBenchmark\n",
      "Spearman:70.90\n",
      "SICKRelatedness\n",
      "Spearman:64.51\n",
      "Avg:69.06\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_original/BSL_unsup_tuning-nreimers-MiniLM-L6-H384-uncased\n",
      "STS12\n",
      "Spearman:64.85\n",
      "STS13\n",
      "Spearman:58.00\n",
      "STS14\n",
      "Spearman:55.66\n",
      "STS15\n",
      "Spearman:74.02\n",
      "STS16\n",
      "Spearman:65.18\n",
      "STSBenchmark\n",
      "Spearman:68.53\n",
      "SICKRelatedness\n",
      "Spearman:63.65\n",
      "Avg:64.27\n",
      "**************************************************\n",
      "\n",
      "Model:output/bsl_original/BSL_unsup_tuning-nreimers-BERT-Small-L-4_H-512_A-8\n",
      "STS12\n",
      "Spearman:70.70\n",
      "STS13\n",
      "Spearman:65.74\n",
      "STS14\n",
      "Spearman:67.29\n",
      "STS15\n",
      "Spearman:80.92\n",
      "STS16\n",
      "Spearman:75.35\n",
      "STSBenchmark\n",
      "Spearman:74.67\n",
      "SICKRelatedness\n",
      "Spearman:65.43\n",
      "Avg:71.44\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pool_mode = 'cls'\n",
    "mlp_mode = True\n",
    "model_list = glob(f'output/bsl_original/BSL_unsup_tuning-*')\n",
    "for model in model_list:\n",
    "    sim_cse = SentenceTransformer(model)\n",
    "    print(f\"Model:{model}\")\n",
    "#     word_embedding_model = models.Transformer(model, max_seq_length=32)\n",
    "#     pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),pooling_mode=pool_mode)\n",
    "#     sim_cse = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    \n",
    "    params = {'task_path': 'SentEval/data/', 'usepytorch': True, 'kfold': 10}\n",
    "    params['encoder'] = sim_cse.encode\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "\n",
    "    transfer_tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    results = se.eval(transfer_tasks)\n",
    "\n",
    "    \n",
    "    spearman_val = 0\n",
    "    for key in results.keys():\n",
    "        print(key)\n",
    "    #     print(results)\n",
    "        if key not in ['STSBenchmark','SICKRelatedness']:\n",
    "            result_temp = results[key]['all']['spearman']['all']\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "        else:\n",
    "            result_temp = results[key]['test']['spearman'].correlation\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "    print(f\"Avg:{(spearman_val/len(results.keys()))*100:.2f}\")\n",
    "    print(f\"*\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCSE (Supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:output/simcse_original/Simcse_original_supervised_bert_base_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:75.51\n",
      "STS13\n",
      "Spearman:83.84\n",
      "STS14\n",
      "Spearman:79.47\n",
      "STS15\n",
      "Spearman:85.50\n",
      "STS16\n",
      "Spearman:80.62\n",
      "STSBenchmark\n",
      "Spearman:83.77\n",
      "SICKRelatedness\n",
      "Spearman:80.20\n",
      "Avg:81.27\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_supervised_roberta_base_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:76.42\n",
      "STS13\n",
      "Spearman:84.47\n",
      "STS14\n",
      "Spearman:79.46\n",
      "STS15\n",
      "Spearman:85.33\n",
      "STS16\n",
      "Spearman:82.60\n",
      "STSBenchmark\n",
      "Spearman:84.96\n",
      "SICKRelatedness\n",
      "Spearman:80.47\n",
      "Avg:81.96\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pool_mode = 'cls'\n",
    "mlp_mode = True\n",
    "model_list = glob(f'output/simcse_original/Simcse_supervised_original_*')\n",
    "for model in model_list:\n",
    "    sim_cse = SentenceTransformer(model)\n",
    "    print(f\"Model:{model}\")\n",
    "#     word_embedding_model = models.Transformer(model, max_seq_length=32)\n",
    "#     pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),pooling_mode=pool_mode)\n",
    "#     sim_cse = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    \n",
    "    params = {'task_path': 'SentEval/data/', 'usepytorch': True, 'kfold': 10}\n",
    "    params['encoder'] = sim_cse.encode\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "\n",
    "    transfer_tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    results = se.eval(transfer_tasks)\n",
    "\n",
    "    \n",
    "    spearman_val = 0\n",
    "    for key in results.keys():\n",
    "        print(key)\n",
    "    #     print(results)\n",
    "        if key not in ['STSBenchmark','SICKRelatedness']:\n",
    "            result_temp = results[key]['all']['spearman']['all']\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "        else:\n",
    "            result_temp = results[key]['test']['spearman'].correlation\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "    print(f\"Avg:{(spearman_val/len(results.keys()))*100:.2f}\")\n",
    "    print(f\"*\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCSE (NLI) Without MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:output/simcse_original/Simcse_original_roberta_base_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:65.25\n",
      "STS13\n",
      "Spearman:79.64\n",
      "STS14\n",
      "Spearman:70.97\n",
      "STS15\n",
      "Spearman:80.51\n",
      "STS16\n",
      "Spearman:77.47\n",
      "STSBenchmark\n",
      "Spearman:76.97\n",
      "SICKRelatedness\n",
      "Spearman:68.11\n",
      "Avg:74.13\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_nreimers_MiniLM_L6_H384_uncased_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:53.35\n",
      "STS13\n",
      "Spearman:67.36\n",
      "STS14\n",
      "Spearman:60.08\n",
      "STS15\n",
      "Spearman:69.37\n",
      "STS16\n",
      "Spearman:68.64\n",
      "STSBenchmark\n",
      "Spearman:62.45\n",
      "SICKRelatedness\n",
      "Spearman:64.85\n",
      "Avg:63.73\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_nreimers_TinyBERT_L_6_H_768_v2_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:65.23\n",
      "STS13\n",
      "Spearman:69.03\n",
      "STS14\n",
      "Spearman:64.08\n",
      "STS15\n",
      "Spearman:76.66\n",
      "STS16\n",
      "Spearman:73.05\n",
      "STSBenchmark\n",
      "Spearman:70.89\n",
      "SICKRelatedness\n",
      "Spearman:70.71\n",
      "Avg:69.95\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_bert_base_uncased_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:63.59\n",
      "STS13\n",
      "Spearman:73.22\n",
      "STS14\n",
      "Spearman:65.88\n",
      "STS15\n",
      "Spearman:77.26\n",
      "STS16\n",
      "Spearman:75.59\n",
      "STSBenchmark\n",
      "Spearman:71.47\n",
      "SICKRelatedness\n",
      "Spearman:69.76\n",
      "Avg:70.97\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_nreimers_BERT_Small_L_4_H_512_A_8_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:61.78\n",
      "STS13\n",
      "Spearman:69.75\n",
      "STS14\n",
      "Spearman:64.56\n",
      "STS15\n",
      "Spearman:76.00\n",
      "STS16\n",
      "Spearman:72.25\n",
      "STSBenchmark\n",
      "Spearman:68.40\n",
      "SICKRelatedness\n",
      "Spearman:65.30\n",
      "Avg:68.29\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_google_mobilebert_uncased_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:13.19\n",
      "STS13\n",
      "Spearman:15.15\n",
      "STS14\n",
      "Spearman:9.28\n",
      "STS15\n",
      "Spearman:5.69\n",
      "STS16\n",
      "Spearman:14.25\n",
      "STSBenchmark\n",
      "Spearman:7.99\n",
      "SICKRelatedness\n",
      "Spearman:17.06\n",
      "Avg:11.80\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_microsoft_MiniLM_L12_H384_uncased_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:52.84\n",
      "STS13\n",
      "Spearman:65.91\n",
      "STS14\n",
      "Spearman:59.16\n",
      "STS15\n",
      "Spearman:71.05\n",
      "STS16\n",
      "Spearman:67.98\n",
      "STSBenchmark\n",
      "Spearman:63.05\n",
      "SICKRelatedness\n",
      "Spearman:61.87\n",
      "Avg:63.12\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_distilbert_base_cased_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:62.87\n",
      "STS13\n",
      "Spearman:71.89\n",
      "STS14\n",
      "Spearman:65.69\n",
      "STS15\n",
      "Spearman:75.85\n",
      "STS16\n",
      "Spearman:73.16\n",
      "STSBenchmark\n",
      "Spearman:70.08\n",
      "SICKRelatedness\n",
      "Spearman:65.34\n",
      "Avg:69.27\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_nreimers_albert_small_v2_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:57.90\n",
      "STS13\n",
      "Spearman:64.98\n",
      "STS14\n",
      "Spearman:60.03\n",
      "STS15\n",
      "Spearman:72.81\n",
      "STS16\n",
      "Spearman:70.75\n",
      "STSBenchmark\n",
      "Spearman:67.51\n",
      "SICKRelatedness\n",
      "Spearman:65.41\n",
      "Avg:65.63\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_nreimers_BERT_Mini_L_4_H_256_A_4_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:60.19\n",
      "STS13\n",
      "Spearman:65.54\n",
      "STS14\n",
      "Spearman:61.35\n",
      "STS15\n",
      "Spearman:74.05\n",
      "STS16\n",
      "Spearman:71.63\n",
      "STSBenchmark\n",
      "Spearman:66.03\n",
      "SICKRelatedness\n",
      "Spearman:62.81\n",
      "Avg:65.94\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_nreimers_BERT_Tiny_L_2_H_128_A_2_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:58.97\n",
      "STS13\n",
      "Spearman:69.75\n",
      "STS14\n",
      "Spearman:62.37\n",
      "STS15\n",
      "Spearman:73.97\n",
      "STS16\n",
      "Spearman:69.15\n",
      "STSBenchmark\n",
      "Spearman:64.90\n",
      "SICKRelatedness\n",
      "Spearman:59.43\n",
      "Avg:65.51\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_nreimers_MiniLM_L3_H384_uncased_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:51.92\n",
      "STS13\n",
      "Spearman:56.46\n",
      "STS14\n",
      "Spearman:53.57\n",
      "STS15\n",
      "Spearman:67.76\n",
      "STS16\n",
      "Spearman:62.69\n",
      "STSBenchmark\n",
      "Spearman:56.65\n",
      "SICKRelatedness\n",
      "Spearman:58.36\n",
      "Avg:58.20\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_nreimers_TinyBERT_L_4_H_312_v2_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:61.59\n",
      "STS13\n",
      "Spearman:67.80\n",
      "STS14\n",
      "Spearman:60.21\n",
      "STS15\n",
      "Spearman:72.54\n",
      "STS16\n",
      "Spearman:67.24\n",
      "STSBenchmark\n",
      "Spearman:65.13\n",
      "SICKRelatedness\n",
      "Spearman:67.87\n",
      "Avg:66.05\n",
      "**************************************************\n",
      "\n",
      "Model:output/simcse_original/Simcse_original_roberta_large_cls_MLPTrue_wikiFalse_nliTrue\n",
      "STS12\n",
      "Spearman:65.43\n",
      "STS13\n",
      "Spearman:79.83\n",
      "STS14\n",
      "Spearman:71.47\n",
      "STS15\n",
      "Spearman:81.89\n",
      "STS16\n",
      "Spearman:76.73\n",
      "STSBenchmark\n",
      "Spearman:76.97\n",
      "SICKRelatedness\n",
      "Spearman:70.94\n",
      "Avg:74.75\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pool_mode = 'cls'\n",
    "mlp_mode = True\n",
    "model_list = glob(f'output/simcse_original/Simcse_original_*{pool_mode}*MLP{mlp_mode}_wikiFalse_nliTrue')\n",
    "for model in model_list:\n",
    "    sim_cse = SentenceTransformer(model)\n",
    "    print(f\"Model:{model}\")\n",
    "#     word_embedding_model = models.Transformer(model, max_seq_length=32)\n",
    "#     pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),pooling_mode=pool_mode)\n",
    "#     sim_cse = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    \n",
    "    params = {'task_path': 'SentEval/data/', 'usepytorch': True, 'kfold': 10}\n",
    "    params['encoder'] = sim_cse.encode\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "\n",
    "    transfer_tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    results = se.eval(transfer_tasks)\n",
    "\n",
    "    \n",
    "    spearman_val = 0\n",
    "    for key in results.keys():\n",
    "        print(key)\n",
    "    #     print(results)\n",
    "        if key not in ['STSBenchmark','SICKRelatedness']:\n",
    "            result_temp = results[key]['all']['spearman']['all']\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "        else:\n",
    "            result_temp = results[key]['test']['spearman'].correlation\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "    print(f\"Avg:{(spearman_val/len(results.keys()))*100:.2f}\")\n",
    "    print(f\"*\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCSE (Wiki1M) Without MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/m_sentence_embedding/SBERT/SentEval/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "/workspace/m_sentence_embedding/SBERT/SentEval/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:output/Simcse_original_BERT_original_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:68.64\n",
      "STS13\n",
      "Spearman:82.36\n",
      "STS14\n",
      "Spearman:74.30\n",
      "STS15\n",
      "Spearman:80.69\n",
      "STS16\n",
      "Spearman:78.71\n",
      "STSBenchmark\n",
      "Spearman:76.56\n",
      "SICKRelatedness\n",
      "Spearman:72.23\n",
      "Avg:76.21\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_nreimers_albert_small_v2_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:55.05\n",
      "STS13\n",
      "Spearman:69.71\n",
      "STS14\n",
      "Spearman:62.58\n",
      "STS15\n",
      "Spearman:72.92\n",
      "STS16\n",
      "Spearman:72.38\n",
      "STSBenchmark\n",
      "Spearman:67.77\n",
      "SICKRelatedness\n",
      "Spearman:66.13\n",
      "Avg:66.65\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_nreimers_BERT_Mini_L_4_H_256_A_4_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:56.55\n",
      "STS13\n",
      "Spearman:65.77\n",
      "STS14\n",
      "Spearman:59.55\n",
      "STS15\n",
      "Spearman:72.26\n",
      "STS16\n",
      "Spearman:70.23\n",
      "STSBenchmark\n",
      "Spearman:60.85\n",
      "SICKRelatedness\n",
      "Spearman:62.19\n",
      "Avg:63.91\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_nreimers_MiniLM_L6_H384_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:54.21\n",
      "STS13\n",
      "Spearman:65.43\n",
      "STS14\n",
      "Spearman:54.96\n",
      "STS15\n",
      "Spearman:65.92\n",
      "STS16\n",
      "Spearman:65.27\n",
      "STSBenchmark\n",
      "Spearman:59.13\n",
      "SICKRelatedness\n",
      "Spearman:63.52\n",
      "Avg:61.21\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_bert_large_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:69.54\n",
      "STS13\n",
      "Spearman:83.99\n",
      "STS14\n",
      "Spearman:75.72\n",
      "STS15\n",
      "Spearman:84.13\n",
      "STS16\n",
      "Spearman:78.43\n",
      "STSBenchmark\n",
      "Spearman:78.44\n",
      "SICKRelatedness\n",
      "Spearman:74.16\n",
      "Avg:77.77\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_distilbert_base_cased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:61.54\n",
      "STS13\n",
      "Spearman:75.67\n",
      "STS14\n",
      "Spearman:68.57\n",
      "STS15\n",
      "Spearman:76.67\n",
      "STS16\n",
      "Spearman:74.89\n",
      "STSBenchmark\n",
      "Spearman:72.67\n",
      "SICKRelatedness\n",
      "Spearman:68.17\n",
      "Avg:71.17\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_nreimers_TinyBERT_L_4_H_312_v2_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:61.77\n",
      "STS13\n",
      "Spearman:69.82\n",
      "STS14\n",
      "Spearman:60.54\n",
      "STS15\n",
      "Spearman:71.06\n",
      "STS16\n",
      "Spearman:69.94\n",
      "STSBenchmark\n",
      "Spearman:66.55\n",
      "SICKRelatedness\n",
      "Spearman:66.81\n",
      "Avg:66.64\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_roberta_base_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:69.20\n",
      "STS13\n",
      "Spearman:81.84\n",
      "STS14\n",
      "Spearman:73.99\n",
      "STS15\n",
      "Spearman:82.42\n",
      "STS16\n",
      "Spearman:81.77\n",
      "STSBenchmark\n",
      "Spearman:81.20\n",
      "SICKRelatedness\n",
      "Spearman:69.25\n",
      "Avg:77.10\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_nreimers_BERT_Tiny_L_2_H_128_A_2_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:58.59\n",
      "STS13\n",
      "Spearman:69.52\n",
      "STS14\n",
      "Spearman:60.15\n",
      "STS15\n",
      "Spearman:69.93\n",
      "STS16\n",
      "Spearman:67.85\n",
      "STSBenchmark\n",
      "Spearman:61.77\n",
      "SICKRelatedness\n",
      "Spearman:60.27\n",
      "Avg:64.01\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_roberta_large_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:70.90\n",
      "STS13\n",
      "Spearman:84.11\n",
      "STS14\n",
      "Spearman:76.18\n",
      "STS15\n",
      "Spearman:84.25\n",
      "STS16\n",
      "Spearman:80.78\n",
      "STSBenchmark\n",
      "Spearman:81.54\n",
      "SICKRelatedness\n",
      "Spearman:70.84\n",
      "Avg:78.37\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_google_mobilebert_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:13.19\n",
      "STS13\n",
      "Spearman:15.15\n",
      "STS14\n",
      "Spearman:9.28\n",
      "STS15\n",
      "Spearman:5.69\n",
      "STS16\n",
      "Spearman:14.25\n",
      "STSBenchmark\n",
      "Spearman:7.99\n",
      "SICKRelatedness\n",
      "Spearman:17.06\n",
      "Avg:11.80\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_nreimers_BERT_Small_L_4_H_512_A_8_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:59.86\n",
      "STS13\n",
      "Spearman:73.92\n",
      "STS14\n",
      "Spearman:66.36\n",
      "STS15\n",
      "Spearman:76.10\n",
      "STS16\n",
      "Spearman:74.60\n",
      "STSBenchmark\n",
      "Spearman:68.85\n",
      "SICKRelatedness\n",
      "Spearman:64.23\n",
      "Avg:69.13\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_bert_base_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:66.27\n",
      "STS13\n",
      "Spearman:77.51\n",
      "STS14\n",
      "Spearman:72.04\n",
      "STS15\n",
      "Spearman:78.63\n",
      "STS16\n",
      "Spearman:77.70\n",
      "STSBenchmark\n",
      "Spearman:75.79\n",
      "SICKRelatedness\n",
      "Spearman:70.67\n",
      "Avg:74.09\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_nreimers_TinyBERT_L_6_H_768_v2_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:61.35\n",
      "STS13\n",
      "Spearman:77.55\n",
      "STS14\n",
      "Spearman:67.78\n",
      "STS15\n",
      "Spearman:76.84\n",
      "STS16\n",
      "Spearman:72.04\n",
      "STSBenchmark\n",
      "Spearman:69.24\n",
      "SICKRelatedness\n",
      "Spearman:69.19\n",
      "Avg:70.57\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_nreimers_MiniLM_L3_H384_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:43.60\n",
      "STS13\n",
      "Spearman:57.88\n",
      "STS14\n",
      "Spearman:51.21\n",
      "STS15\n",
      "Spearman:63.70\n",
      "STS16\n",
      "Spearman:62.09\n",
      "STSBenchmark\n",
      "Spearman:46.92\n",
      "SICKRelatedness\n",
      "Spearman:54.20\n",
      "Avg:54.23\n",
      "**************************************************\n",
      "\n",
      "Model:output/Simcse_original_microsoft_MiniLM_L12_H384_uncased_cls_MLPTrue\n",
      "STS12\n",
      "Spearman:60.58\n",
      "STS13\n",
      "Spearman:72.67\n",
      "STS14\n",
      "Spearman:63.75\n",
      "STS15\n",
      "Spearman:71.21\n",
      "STS16\n",
      "Spearman:71.19\n",
      "STSBenchmark\n",
      "Spearman:68.45\n",
      "SICKRelatedness\n",
      "Spearman:65.72\n",
      "Avg:67.65\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pool_mode = 'cls'\n",
    "mlp_mode = True\n",
    "model_list = glob(f'output/Simcse_original_*{pool_mode}*MLP{mlp_mode}*')\n",
    "# model_list = ['output/Simcse_original_bert_base_uncased_cls_MLPTrue']\n",
    "# model_list = glob(f'output/Simcse_original_*large*{pool_mode}*MLP{mlp_mode}*')\n",
    "for model in model_list:\n",
    "#     sim_cse = SentenceTransformer(model)\n",
    "    word_embedding_model = models.Transformer(model, max_seq_length=32)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),pooling_mode=pool_mode)\n",
    "    sim_cse = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    \n",
    "    params = {'task_path': 'SentEval/data/', 'usepytorch': True, 'kfold': 10}\n",
    "    params['encoder'] = sim_cse.encode\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "\n",
    "    transfer_tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    results = se.eval(transfer_tasks)\n",
    "\n",
    "    print(f\"Model:{model}\")\n",
    "    spearman_val = 0\n",
    "    for key in results.keys():\n",
    "        print(key)\n",
    "    #     print(results)\n",
    "        if key not in ['STSBenchmark','SICKRelatedness']:\n",
    "            result_temp = results[key]['all']['spearman']['all']\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "        else:\n",
    "            result_temp = results[key]['test']['spearman'].correlation\n",
    "            spearman_val+=result_temp\n",
    "            print(f\"Spearman:{result_temp*100:.2f}\")\n",
    "    print(f\"Avg:{(spearman_val/len(results.keys()))*100:.2f}\")\n",
    "    print(f\"*\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
