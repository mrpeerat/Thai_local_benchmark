{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess [Thai Common Voice Corpus 7.0](https://commonvoice.mozilla.org/en/datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook by [@tann9949](https://github.com/tann9949)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydub\n",
    "# !pip install pythainlp==2.3.1\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "from spell_correction import format_repeat\n",
    "\n",
    "# ipython\n",
    "import IPython.display as ipd\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_root: str = \"../data/cv-corpus-7.0-2021-07-21\"\n",
    "\n",
    "train: pd.DataFrame = pd.read_csv(f\"{cv_root}/th/train.tsv\", delimiter=\"\\t\")\n",
    "train[\"set\"] = \"train\"\n",
    "dev: pd.DataFrame = pd.read_csv(f\"{cv_root}/th/dev.tsv\", delimiter=\"\\t\")\n",
    "dev[\"set\"] = \"dev\"\n",
    "test: pd.DataFrame = pd.read_csv(f\"{cv_root}/th/test.tsv\", delimiter=\"\\t\")\n",
    "test[\"set\"] = \"test\"\n",
    "data: pd.DataFrame = pd.concat([train, dev, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "command: str = \"sox {mp3_path} -t wav -r {sr} -c 1 -b 16 - |\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_path(cv_root: str, path: str) -> str:\n",
    "    \"\"\"Get full path from `path` instance in cv data\"\"\"\n",
    "    f_path: str = f\"{cv_root}/th/clips/{path}\"\n",
    "    if not os.path.exists(f_path):\n",
    "        raise FileNotFoundError(f\"File `{f_path}` does not exists\")\n",
    "    return f_path\n",
    "\n",
    "\n",
    "def get_char(texts: List[str]) -> List[str]:\n",
    "    \"\"\"Get unique char from list of documents\"\"\"\n",
    "    return sorted(set([char for sent in texts for char in sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules mapping obtained from exploring data\n",
    "mapping_char: Dict[str, str] = {\n",
    "    r\"!\": \" \",\n",
    "    r'\"': \" \",\n",
    "    r\"'\": \" \",\n",
    "    r\",\": \" \",\n",
    "    r\"-\": \" \",\n",
    "    r\".*\\..*\\..*\": \" \",\n",
    "    r\"\\.$\": \"\",  # full stop at end of sentence\n",
    "    r\"([ก-์])\\.([ก-์])\": r\"\\1. \\2\",  # บจก.XXX -> บจก. XXX\n",
    "    r\":\": \" \",\n",
    "    r\";\": \" \",\n",
    "    r\"\\?\": \" \",\n",
    "    r\"‘\": \" \", \n",
    "    r\"’\": \" \",\n",
    "    r\"“\": \" \", \n",
    "    r\"”\": \" \",\n",
    "    r\"~\": \" \",\n",
    "    r\"—\": \" \"\n",
    "}\n",
    "\n",
    "# text that needs to be fixed\n",
    "change_text: Dict[str, str] = {\n",
    "    \"common_voice_th_26103939.mp3\": \"บริษัทจำกัดดาบเพ็ชร์\",\n",
    "    \"common_voice_th_27269555.mp3\": \"ศุนย์การค้า เจ.พี.ไรวา\",\n",
    "    \"common_voice_th_26429486.mp3\": \"โศรดาพลัดถิ่น ชอุ่ม ปัญจพรรค์\",\n",
    "    \"common_voice_th_25668677.mp3\": \"มิสเตอร์ ลินคอล์น\",\n",
    "    \"common_voice_th_25677501.mp3\": \"โอ้พระเจ้าพวกเขาฆ่า เคนนี่\",\n",
    "    \"common_voice_th_25696778.mp3\": \"ฉันสงสัยว่า ซี เซคชั่น จะได้รับความนิยมมากกว่าการเกิดตามธรรมชาติในวันหนึ่ง\",\n",
    "    \"common_voice_th_25728649.mp3\": \"เนื่องจากการขาดโปรแกรมความผิดพลาด โจฮันน่า จึงตัดสินใจขายการหาประโยชน์ในตลาดมืด\",\n",
    "    \"common_voice_th_25700969.mp3\": \"บรูค วิจารณ์ตัวเองเพราะรอยยิ้ม\",\n",
    "    \"common_voice_th_23897115.mp3\": \"กลุ่มอาการ แอสเพอร์เจอร์ เป็นรูปแบบของออทิสติก\",\n",
    "    \"common_voice_th_25705973.mp3\": \"การเปิดใช้งาน ซอฟต์แม็ก นั้นมีราคาแพงมากเพื่อใช้ในการคำนวณ\",\n",
    "    \"common_voice_th_24149507.mp3\": \"แอสโทเทริฟ ถูกใช้ปูพื้นในสนามเด็กเล่นกลางแจ้ง\",\n",
    "    \"common_voice_th_25665768.mp3\": \"เฟสบุ๊ก รวบรวมข้อมูลเกี่ยวกับผู้ที่ไม่ได้เป็นสมาชิก\",\n",
    "    \"common_voice_th_25636404.mp3\": \"ใครอยู่ ม. โปรดพาอ้อมไปกินข้าวที\",\n",
    "    \"common_voice_th_25903042.mp3\": \"ฉันคิดว่ามันพร้อมแล้ว ฉันกล่าว\",\n",
    "    \"common_voice_th_26701409.mp3\": \"จอมพล ป. มีแนวคิดว่าราษฎรจะรักชาติของตนมิได้\",\n",
    "    \"common_voice_th_26147573.mp3\": \"จอมพล ป. พิบูลสงคราม\",\n",
    "    \"common_voice_th_25900743.mp3\": \"ไม่ใช่เพื่อคุณ กัซซี่กล่าว\",\n",
    "    \"common_voice_th_25682485.mp3\": \"ขอขอบคุณ จะตรวจสอบอย่างแน่นอน\",\n",
    "    \"common_voice_th_25885519.mp3\": \"ไม่ใช่อะไรสลักสำคัญ ทหารตอบกลับ\",\n",
    "    \"common_voice_th_25899784.mp3\": \"ไม่ใช่อย่างน้อยที่สุด เขากล่าว\",\n",
    "    \"common_voice_th_25704992.mp3\": \"การวินิจฉัยโรคจำเป็นต้องทำอย่างละเอียดและรอบคอบ\", # การวินิจฉัยโรคจําเป็นต้องทําอย่างละเอียดและรอบคอบ\n",
    "    \"common_voice_th_25628971.mp3\": \"เขากำลังทำงานอยู่\",  # \"เขากำลังทํางานอยู่\"\n",
    "}\n",
    "\n",
    "# sentence to skip\n",
    "skip_sentence: Dict[str, str] = {\n",
    "    \"common_voice_th_25683553.mp3\": \"บางครั้งคนอังกฤษก็ใช้คำว่า whilst แม้ว่ามันจะดูเก่าไปแล้วก็ตาม\",\n",
    "    \"common_voice_th_25682645.mp3\": \"ฉันใช้Flickr ในการเก็บภาพถ่ายออนไลน์ที่สำคัญของฉันเป็นส่วนใหญ่\",\n",
    "    \"common_voice_th_25673002.mp3\": \"Fury X เป็นการ์ดกราฟิกที่ทรงพลังมาก\",\n",
    "    \"common_voice_th_25695730.mp3\": \"Brexiteers เป็นชื่อเล่นที่มอบให้กับผู้ที่สนับสนุนการลงประชามติของ Brexit\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Audio EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_len(audio_path: str) -> float:\n",
    "    \"\"\"Get audio duration in second\"\"\"\n",
    "    audio: AudioSegment = AudioSegment.from_mp3(audio_path)\n",
    "    return len(audio) / 1000  # pydub duration works in ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios: List[str] = train[\"path\"].map(lambda path: get_full_path(cv_root=cv_root, path=path)).tolist()\n",
    "audios_len: List[float] = [get_audio_len(f) for f in tqdm(audios)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(audios_len, bins=50)\n",
    "plt.xlabel(\"Time (sec)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"File duration distribution\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean: {np.mean(audios_len):.2f}\")\n",
    "print(f\"Std.: {np.std(audios_len):.2f}\")\n",
    "print(f\"Max: {np.max(audios_len):.2f}\")\n",
    "print(f\"Min: {np.min(audios_len):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Transcription EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts: pd.DataFrame = data[[\"path\", \"sentence\"]]\n",
    "texts[\"path\"] = texts[\"path\"].map(lambda x: get_full_path(cv_root, x))\n",
    "texts: List[Tuple[str, str]] = texts.values.tolist()\n",
    "# texts = [correct_sentence(text) for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = [print(f\"`{c}`, \", end=\"\") for c in get_char([x[-1] for x in texts])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nxt_btn = widgets.Button(description=\"Next\")\n",
    "back_btn = widgets.Button(description=\"Back\")\n",
    "output = widgets.Output()\n",
    "\n",
    "pattern = r\"—\"\n",
    "idx = 0\n",
    "\n",
    "def on_nxt_clicked(b):\n",
    "    global idx\n",
    "    is_match = False\n",
    "    terminate = False\n",
    "    while not is_match:\n",
    "        if idx == len(texts) - 1:\n",
    "            is_match = True\n",
    "            terminate = True\n",
    "        f_path, sent = texts[idx]\n",
    "        matches = re.finditer(pattern, sent)\n",
    "        n_matches: int = sum([1 for _ in matches])\n",
    "        if n_matches > 0:\n",
    "            is_match = True\n",
    "        idx += 1\n",
    "    with output:\n",
    "        if terminate:\n",
    "            ipd.clear_output()\n",
    "            print(\"End of corpus. Resetting...\")\n",
    "            idx = 0\n",
    "        else:\n",
    "            ipd.clear_output()\n",
    "            print(f_path)\n",
    "            print(f\"{sent}\")\n",
    "            !afplay $f_path\n",
    "            ipd.display(ipd.Audio(f_path))\n",
    "\n",
    "def on_back_clicked(b):\n",
    "    global idx\n",
    "    is_match = False\n",
    "    terminate = False\n",
    "    while not is_match:\n",
    "        if idx == 0:\n",
    "            is_match = True\n",
    "            terminate = True\n",
    "        f_path, sent = texts[idx]\n",
    "        matches = re.finditer(pattern, sent)\n",
    "        n_matches: int = sum([1 for _ in matches])\n",
    "        if n_matches > 0:\n",
    "            is_match = True\n",
    "        idx =- 1\n",
    "    with output:\n",
    "        if terminate:\n",
    "            ipd.clear_output()\n",
    "            idx = 0\n",
    "        else:\n",
    "            ipd.clear_output()\n",
    "            print(f_path)\n",
    "            print(f\"{sent}\")\n",
    "            !afplay $f_path\n",
    "            ipd.display(ipd.Audio(f_path))\n",
    "\n",
    "\n",
    "display(nxt_btn, back_btn, output)\n",
    "\n",
    "nxt_btn.on_click(on_nxt_clicked)\n",
    "back_btn.on_click(on_back_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[-1] for x in texts if \"—\" in x[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!afplay data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25636404.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Preprocess text according to `mapping_char`\"\"\"\n",
    "    text = format_repeat(text)\n",
    "    for pattern, sub in mapping_char.items():\n",
    "        text = re.sub(pattern, sub, text)\n",
    "    text = re.sub(r\" +\", \" \", text)  # merge multiple whitespaces to one\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25900743.mp3\n",
      "\tReplacing `ไม่ใช่เพื่อคุณ. กัซซี่กล่าว`... with `ไม่ใช่เพื่อคุณ กัซซี่กล่าว`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25903042.mp3\n",
      "\tReplacing `ฉันคิดว่ามันพร้อมแล้ว. ฉันกล่าว`... with `ฉันคิดว่ามันพร้อมแล้ว ฉันกล่าว`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_26103939.mp3\n",
      "\tReplacing `บจก. ดาบเพ็ชร์`... with `บริษัทจำกัดดาบเพ็ชร์`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_26429486.mp3\n",
      "\tReplacing `โศรดาพลัดถิ่น ชอุ่มปํญจพรรค์`... with `โศรดาพลัดถิ่น ชอุ่ม ปัญจพรรค์`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_26701409.mp3\n",
      "\tReplacing `จอมพลป. มีแนวคิดว่าราษฎรจะรักชาติของตนมิได้`... with `จอมพล ป. มีแนวคิดว่าราษฎรจะรักชาติของตนมิได้`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_27269555.mp3\n",
      "\tReplacing ` `... with `ศุนย์การค้า เจ.พี.ไรวา`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25668677.mp3\n",
      "\tReplacing `MrLincolnเป็นที่ปรึกษาของฉัน`... with `มิสเตอร์ ลินคอล์น`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25677501.mp3\n",
      "\tReplacing `โอ้พระเจ้าพวกเขาฆ่าKenny `... with `โอ้พระเจ้าพวกเขาฆ่า เคนนี่`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25636404.mp3\n",
      "\tReplacing `ใครอยู่ม. โปรดพาอ้อมไปกินข้าวที`... with `ใครอยู่ ม. โปรดพาอ้อมไปกินข้าวที`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25683553.mp3\n",
      "\tRemoving `บางครั้งคนอังกฤษก็ใช้คำว่าwhilstแม้ว่ามันจะดูเก่าไปแล้วก็ตาม`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_26147573.mp3\n",
      "\tReplacing `จอมพลป. พิบูลสงคราม`... with `จอมพล ป. พิบูลสงคราม`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25682485.mp3\n",
      "\tReplacing `ขอขอบคุณ. จะตรวจสอบอย่างแน่นอน`... with `ขอขอบคุณ จะตรวจสอบอย่างแน่นอน`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25885519.mp3\n",
      "\tReplacing `ไม่ใช่อะไรสลักสำคัญ. ทหารตอบกลับ`... with `ไม่ใช่อะไรสลักสำคัญ ทหารตอบกลับ`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25899784.mp3\n",
      "\tReplacing `ไม่ใช่อย่างน้อยที่สุด. เขากล่าว`... with `ไม่ใช่อย่างน้อยที่สุด เขากล่าว`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25696778.mp3\n",
      "\tReplacing `ฉันสงสัยว่าC sectionจะได้รับความนิยมมากกว่าการเกิดตามธรรมชาติในวันหนึ่ง`... with `ฉันสงสัยว่า ซี เซคชั่น จะได้รับความนิยมมากกว่าการเกิดตามธรรมชาติในวันหนึ่ง`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25728649.mp3\n",
      "\tReplacing `เนื่องจากการขาดโปรแกรมความผิดพลาดJohannaจึงตัดสินใจขายการหาประโยชน์ในตลาดมืด`... with `เนื่องจากการขาดโปรแกรมความผิดพลาด โจฮันน่า จึงตัดสินใจขายการหาประโยชน์ในตลาดมืด`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25700969.mp3\n",
      "\tReplacing `Burkeวิจารณ์ตัวเองเพราะรอยยิ้ม`... with `บรูค วิจารณ์ตัวเองเพราะรอยยิ้ม`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25682645.mp3\n",
      "\tRemoving `ฉันใช้Flickrในการเก็บภาพถ่ายออนไลน์ที่สำคัญของฉันเป็นส่วนใหญ่`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_23897115.mp3\n",
      "\tReplacing `กลุ่มอาการAspergerเป็นรูปแบบของออทิสติก`... with `กลุ่มอาการ แอสเพอร์เจอร์ เป็นรูปแบบของออทิสติก`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25704992.mp3\n",
      "\tReplacing `การวินิจฉัยโรคจําเป็นต้องทําอย่างละเอียดและรอบคอบ`... with `การวินิจฉัยโรคจำเป็นต้องทำอย่างละเอียดและรอบคอบ`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25628971.mp3\n",
      "\tReplacing `เขากำลังทํางานอยู่`... with `เขากำลังทำงานอยู่`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25705973.mp3\n",
      "\tReplacing `การเปิดใช้งานsoftmaxนั้นมีราคาแพงมากเพื่อใช้ในการคำนวณ`... with `การเปิดใช้งาน ซอฟต์แม็ก นั้นมีราคาแพงมากเพื่อใช้ในการคำนวณ`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_24149507.mp3\n",
      "\tReplacing `Astroturfถูกใช้ปูพื้นในสนามเด็กเล่นกลางแจ้ง`... with `แอสโทเทริฟ ถูกใช้ปูพื้นในสนามเด็กเล่นกลางแจ้ง`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25673002.mp3\n",
      "\tRemoving `FuryXเป็นการ์ดกราฟิกที่ทรงพลังมาก`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25665768.mp3\n",
      "\tReplacing `Facebookรวบรวมข้อมูลเกี่ยวกับผู้ที่ไม่ได้เป็นสมาชิก`... with `เฟสบุ๊ก รวบรวมข้อมูลเกี่ยวกับผู้ที่ไม่ได้เป็นสมาชิก`...\n",
      "../data/cv-corpus-7.0-2021-07-21/th/clips/common_voice_th_25695730.mp3\n",
      "\tRemoving `Brexiteersเป็นชื่อเล่นที่มอบให้กับผู้ที่สนับสนุนการลงประชามติของBrexit`...\n"
     ]
    }
   ],
   "source": [
    "texts: pd.DataFrame = data[[\"path\", \"sentence\", \"set\"]]\n",
    "texts[\"path\"] = texts[\"path\"].map(lambda x: get_full_path(cv_root, x))\n",
    "texts[\"sentence\"] = texts[\"sentence\"].map(lambda x: preprocess_text(x))\n",
    "\n",
    "remove_idx: List[int] = []\n",
    "for i in range(len(texts)):\n",
    "    f_path: str = os.path.basename(texts.loc[i, \"path\"])\n",
    "    for name, change in change_text.items():\n",
    "        if f_path in name:\n",
    "            print(texts.loc[i, \"path\"])\n",
    "            print(\"\\tReplacing\", f\"`{texts.loc[i, 'sentence']}`...\", \"with\", f\"`{change}`...\")\n",
    "            texts.loc[i, \"sentence\"] = change\n",
    "            break\n",
    "    for name in skip_sentence.keys():\n",
    "        if f_path in name:\n",
    "            print(texts.loc[i, \"path\"])\n",
    "            print(f\"\\tRemoving `{texts.loc[i, 'sentence']}`...\")\n",
    "            remove_idx.append(i)\n",
    "            \n",
    "texts = texts.drop(texts.index[remove_idx])\n",
    "            \n",
    "texts[\"path\"] = texts[\"path\"].map(lambda x: x.replace(f\"{cv_root}/th/clips/\", \"\"))\n",
    "texts = texts.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" \", \".\", \"ก\", \"ข\", \"ฃ\", \"ค\", \"ฆ\", \"ง\", \"จ\", \"ฉ\", \"ช\", \"ซ\", \"ฌ\", \"ญ\", \"ฎ\", \"ฏ\", \"ฐ\", \"ฑ\", \"ฒ\", \"ณ\", \"ด\", \"ต\", \"ถ\", \"ท\", \"ธ\", \"น\", \"บ\", \"ป\", \"ผ\", \"ฝ\", \"พ\", \"ฟ\", \"ภ\", \"ม\", \"ย\", \"ร\", \"ฤ\", \"ล\", \"ว\", \"ศ\", \"ษ\", \"ส\", \"ห\", \"ฬ\", \"อ\", \"ฮ\", \"ฯ\", \"ะ\", \"ั\", \"า\", \"ำ\", \"ิ\", \"ี\", \"ึ\", \"ื\", \"ุ\", \"ู\", \"เ\", \"แ\", \"โ\", \"ใ\", \"ไ\", \"ๅ\", \"็\", \"่\", \"้\", \"๊\", \"๋\", \"์\", "
     ]
    }
   ],
   "source": [
    "_ = [print(f\"\\\"{c}\\\", \", end=\"\") for c in get_char([x[1] for x in texts.values.tolist()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('common_voice_th_26057680.mp3', 'หจก. ธรรมเมธาพืชผล'),\n",
       " ('common_voice_th_26167946.mp3', 'หจก. ศิวะวรเวท'),\n",
       " ('common_voice_th_26167354.mp3', 'บมจ. ทีฆะและเพื่อน'),\n",
       " ('common_voice_th_26052276.mp3', 'บจก. น้ำทิพย์'),\n",
       " ('common_voice_th_26061574.mp3', 'หจก. แต้กุลภาพยนตร์'),\n",
       " ('common_voice_th_26701409.mp3',\n",
       "  'จอมพล ป. มีแนวคิดว่าราษฎรจะรักชาติของตนมิได้'),\n",
       " ('common_voice_th_26050940.mp3', 'บมจ. ปรีชากุลเศรษฐ์บรรจุภัณฑ์'),\n",
       " ('common_voice_th_26081408.mp3', 'หจก. เตมิยะเดชแพคกิ้ง'),\n",
       " ('common_voice_th_26131457.mp3', 'บจก. ตวันเยี่ยม'),\n",
       " ('common_voice_th_26148908.mp3', 'หจก. ธัญเสถียรภาพยนตร์'),\n",
       " ('common_voice_th_26161189.mp3', 'หจก. มนทอง'),\n",
       " ('common_voice_th_26161545.mp3', 'หจก. ร่มธิติรัตน์'),\n",
       " ('common_voice_th_26339914.mp3', 'ป. พิบูลสงคราม'),\n",
       " ('common_voice_th_26074257.mp3', 'หจก. เยาวธนโชค'),\n",
       " ('common_voice_th_27269555.mp3', 'ศุนย์การค้า เจ.พี.ไรวา'),\n",
       " ('common_voice_th_25636404.mp3', 'ใครอยู่ ม. โปรดพาอ้อมไปกินข้าวที'),\n",
       " ('common_voice_th_26120971.mp3', 'หจก. นาถะพินธุมอเตอร์'),\n",
       " ('common_voice_th_26147573.mp3', 'จอมพล ป. พิบูลสงคราม'),\n",
       " ('common_voice_th_26153923.mp3', 'หจก. เลขะพันธุ์ก่อสร้าง'),\n",
       " ('common_voice_th_25766210.mp3', 'กกต. มีหน้าที่กำกับดูแลการเลือกตั้ง'),\n",
       " ('common_voice_th_25660507.mp3',\n",
       "  'กสพท. ประกาศรายชื่อผู้มีสิทธิ์สัมภาษณ์แล้ว')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], x[1]) for x in texts[[\"path\", \"sentence\"]].values.tolist() if \".\" in x[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train: pd.DataFrame = texts[texts[\"set\"] == \"train\"][[\"path\", \"sentence\"]]\n",
    "preprocessed_dev: pd.DataFrame = texts[texts[\"set\"] == \"dev\"][[\"path\", \"sentence\"]]\n",
    "preprocessed_test: pd.DataFrame = texts[texts[\"set\"] == \"test\"][[\"path\", \"sentence\"]]\n",
    "\n",
    "preprocessed_train.to_csv(f\"{cv_root}/th/train_cleaned.tsv\", index=False, sep='\\t')\n",
    "preprocessed_dev.to_csv(f\"{cv_root}/th/dev_cleaned.tsv\", index=False, sep='\\t')\n",
    "preprocessed_test.to_csv(f\"{cv_root}/th/test_cleaned.tsv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23332, 2), (23332, 11))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9711, 2), (9712, 11))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dev.shape, dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9709, 2), (9712, 11))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_test.shape, test.shape"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
