{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_from_disk\n",
    "from datasets import DatasetDict\n",
    "import datasets\n",
    "\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/aisg/peerat/Thai_local_benchmark/datasets/*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_name = {\n",
    "    \"north\": [\"ลาบเหนือ\",\n",
    "            \"ขนมจีนน้ำเงี้ยว\",\n",
    "            \"แกงฮังเล\",\n",
    "            \"น้ำพริกหนุ่ม\",\n",
    "            \"น้ำพริกอ่อง\",\n",
    "            \"แกงหัวปลี\",\n",
    "            \"แกงหยวก\",\n",
    "            \"ไส้อั๋ว\",\n",
    "            \"แคบหมู\",\n",
    "            \"แกงกระด้าง\"],\n",
    "    \"east\": [\"แจ่วบักเขือ\",\n",
    "            \"อ่อมน้องวัว\",\n",
    "            \"ตำบักหุ่ง\",\n",
    "            \"หมกหน่อไม้\",\n",
    "            \"ซอยจุ๊\",\n",
    "            \"แกงขี้เหล็ก\",\n",
    "            \"น้ำตกคอหมูย่าง\",\n",
    "            \"ปลาส้ม\",\n",
    "            \"แจ่วฮ้อน\",\n",
    "            \"ตับหวาน\"],\n",
    "    \"south\": [\"แก๋งพุงปลา\",\n",
    "            \"แกงส้ม\",\n",
    "            \"ลอกอผัดไข่\",\n",
    "            \"ข้าวผั๊ดเคย\",\n",
    "            \"แกงส้มปล๊าพงยอดพร๊าว\",\n",
    "            \"ข้าวผั๊ดเคย\",\n",
    "            \"ปล่าซายท๋อดขี้มิ้น\",\n",
    "            \"ผั๊ดผั๊กเหลี๊ยง\",\n",
    "            \"แก๋งเลียง\",\n",
    "            \"ผั๊ดหลูกต๋อ\"],\n",
    "    \"center\": [\"ผัดกระเพราหมูสับไข่ดาว\", \"ต้มยำกุ้ง\", \"ผัดไทกุ้งสด\", \"แกงเขียวหวานไก่\", \"ต้มข่าไก่\",\n",
    "                \"ต้มจืด\",\n",
    "                \"พะโล้\",\n",
    "                \"ทอดมันปลากราย\",\n",
    "                \"เต้าเจี้ยวหลน\",\n",
    "                \"พะแนง\"]\n",
    "}\n",
    "\n",
    "conversation_list = [\n",
    "    \"ประเพณีท้องถิ่น\",\n",
    "    \"อาชีพ\",\n",
    "    \"การคมนาคม\",\n",
    "    \"ครอบครัว\",\n",
    "    \"กลับบ้านช่วงเทศกาล\",\n",
    "    \"การเมืองท้องถิ่น\",\n",
    "    \"สภาพอากาศ\",\n",
    "    \"อาหารท้องถิ่น\",\n",
    "    \"เครื่องแต่งกายท้องถิ่น\",\n",
    "    \"การศึกษาท้องถิ่น\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data = DatasetDict()\n",
    "\n",
    "for local in [\"east\",\"north\",\"south\",\"center\"]:\n",
    "    task_data = DatasetDict()\n",
    "    for file in glob(path):\n",
    "        task_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "        df = pd.read_csv(file)\n",
    "        if task_name == 'qa':\n",
    "            new_df = df[[\"id\",f\"question_{local}\",f'text_2_{local}',f'context_{local}']]\n",
    "            dataset = Dataset.from_pandas(new_df)\n",
    "            dataset = dataset.rename_column(f\"text_2_{local}\", \"text_2\")\n",
    "            dataset = dataset.rename_column(f\"question_{local}\", \"question\")\n",
    "            dataset = dataset.rename_column(f\"context_{local}\", \"context\")\n",
    "            task_data[task_name] = dataset\n",
    "        elif task_name == 'summarization':\n",
    "            new_df = df[[\"id\",f\"text_2_{local}\",\"text_1\"]]\n",
    "            dataset = Dataset.from_pandas(new_df)\n",
    "            dataset = dataset.rename_column(f\"text_2_{local}\", \"text_2\")\n",
    "            task_data[task_name] = dataset\n",
    "        elif 'translation' in task_name:\n",
    "            task_name = f'translation_eng_{local}'\n",
    "            new_df = df[[\"english\",local]]\n",
    "            dataset = Dataset.from_pandas(new_df)\n",
    "            dataset = dataset.rename_column(f\"english\", \"text_1\")\n",
    "            dataset = dataset.rename_column(local, \"text_2\")\n",
    "            task_data[task_name] = dataset\n",
    "\n",
    "            task_name = f'translation_{local}_eng'\n",
    "            new_df = df[[\"english\",local]]\n",
    "            dataset = Dataset.from_pandas(new_df)\n",
    "            dataset = dataset.rename_column(f\"english\", \"text_2\")\n",
    "            dataset = dataset.rename_column(local, \"text_1\")\n",
    "            task_data[task_name] = dataset\n",
    "\n",
    "\n",
    "    # conversation\n",
    "    task_name='conversation'\n",
    "    new_df = pd.DataFrame(list(zip(list(range(len(conversation_list))), conversation_list, \".\"*len(conversation_list))),columns =['id', 'text_1',\"text_2\"])\n",
    "    dataset = Dataset.from_pandas(new_df)\n",
    "    task_data[task_name] = dataset\n",
    "\n",
    "    task_name='food'\n",
    "    food_list = food_name[local]\n",
    "    new_df = pd.DataFrame(list(zip(list(range(len(food_list))), food_list, \".\"*len(food_list))),columns =['id', 'text_1', \"text_2\"])\n",
    "    dataset = Dataset.from_pandas(new_df)\n",
    "    task_data[task_name] = dataset\n",
    "\n",
    "    local_data[local] = task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/dataset.pkl', 'wb') as file:  \n",
    "    # A new file will be created \n",
    "    pickle.dump(local_data, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    east: DatasetDict({\n",
      "        qa: Dataset({\n",
      "            features: ['id', 'question', 'text_2', 'context'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        summarization: Dataset({\n",
      "            features: ['id', 'text_2', 'text_1'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        translation_eng_east: Dataset({\n",
      "            features: ['text_1', 'text_2'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        translation_east_eng: Dataset({\n",
      "            features: ['text_2', 'text_1'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        conversation: Dataset({\n",
      "            features: ['id', 'text_1', 'text_2'],\n",
      "            num_rows: 10\n",
      "        })\n",
      "        food: Dataset({\n",
      "            features: ['id', 'text_1', 'text_2'],\n",
      "            num_rows: 10\n",
      "        })\n",
      "    })\n",
      "    north: DatasetDict({\n",
      "        qa: Dataset({\n",
      "            features: ['id', 'question', 'text_2', 'context'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        summarization: Dataset({\n",
      "            features: ['id', 'text_2', 'text_1'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        translation_eng_north: Dataset({\n",
      "            features: ['text_1', 'text_2'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        translation_north_eng: Dataset({\n",
      "            features: ['text_2', 'text_1'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        conversation: Dataset({\n",
      "            features: ['id', 'text_1', 'text_2'],\n",
      "            num_rows: 10\n",
      "        })\n",
      "        food: Dataset({\n",
      "            features: ['id', 'text_1', 'text_2'],\n",
      "            num_rows: 10\n",
      "        })\n",
      "    })\n",
      "    south: DatasetDict({\n",
      "        qa: Dataset({\n",
      "            features: ['id', 'question', 'text_2', 'context'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        summarization: Dataset({\n",
      "            features: ['id', 'text_2', 'text_1'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        translation_eng_south: Dataset({\n",
      "            features: ['text_1', 'text_2'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        translation_south_eng: Dataset({\n",
      "            features: ['text_2', 'text_1'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        conversation: Dataset({\n",
      "            features: ['id', 'text_1', 'text_2'],\n",
      "            num_rows: 10\n",
      "        })\n",
      "        food: Dataset({\n",
      "            features: ['id', 'text_1', 'text_2'],\n",
      "            num_rows: 10\n",
      "        })\n",
      "    })\n",
      "    center: DatasetDict({\n",
      "        qa: Dataset({\n",
      "            features: ['id', 'question', 'text_2', 'context'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        summarization: Dataset({\n",
      "            features: ['id', 'text_2', 'text_1'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        translation_eng_center: Dataset({\n",
      "            features: ['text_1', 'text_2'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        translation_center_eng: Dataset({\n",
      "            features: ['text_2', 'text_1'],\n",
      "            num_rows: 20\n",
      "        })\n",
      "        conversation: Dataset({\n",
      "            features: ['id', 'text_1', 'text_2'],\n",
      "            num_rows: 10\n",
      "        })\n",
      "        food: Dataset({\n",
      "            features: ['id', 'text_1', 'text_2'],\n",
      "            num_rows: 10\n",
      "        })\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/dataset.pkl', 'rb') as file: \n",
    "      \n",
    "    # Call load method to deserialze \n",
    "    loaded_file = pickle.load(file) \n",
    "  \n",
    "    print(loaded_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_1': \"I rode my motorcycle to buy coffee at the entrance of the alley, only to find that my favorite shop was closed. So, I went to try a new place instead. It wasn't good at all. I wouldn't go buy it there again.\",\n",
       " 'text_2': 'ขับรถเครื่องไปซื้อกาแฟที่หน้าปากซอย แต่ก็พบว่าฮ้านประจำตี้ชอบกิ๋นมันปิดไปแล้ว ก่อเลยขับรถไปซื้อฮ้านใหม่ บ่อลำเลย จะบ่ไปซื้อแหมแล้ว'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_file['north']['translation_eng_north'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
